{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "import re\n",
    "import string\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "def remove_ip(s):\n",
    "    # Replace all ip adresses with '<ip>' tag\n",
    "    ip_regexp = r\"\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b\"\n",
    "    return re.sub(ip_regexp, '<ip>', s)\n",
    "def remove_email(s):\n",
    "    # Replace all email adresses with '<email>' tag\n",
    "    email_regexp = r\"([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})\"\n",
    "    return re.sub(email_regexp, '<email>', s)\n",
    "def remove_mailto(s):\n",
    "    # Replace all \"<mailto:<email>>\" with <email>. Email adresses should be replaced by remove_email first.\n",
    "    return s.replace(\"<mailto:<email>>\", \"<email>\")\n",
    "def remove_url(s):\n",
    "    # Replace all url's with '<url>' tag\n",
    "    url_regexp = r\"((http|ftp|https):\\/\\/)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "    s = re.sub(url_regexp, '<url>', s)\n",
    "    # Sometimes url's are inside <> so we need to replace <<url>> with <url>\n",
    "    return s.replace(\"<<url>>\", \"<url>\")\n",
    "def remove_punc(s, exceptions):\n",
    "    # Remove all punctuation from string with exceptions in list exceptions\n",
    "    remove = string.punctuation\n",
    "    for exception in exceptions:\n",
    "        remove = remove.replace(exception, \"\")\n",
    "    # Create the pattern\n",
    "    pattern = r\"[{}]\".format(remove)\n",
    "\n",
    "    return re.sub(pattern, \"\", s)\n",
    "def remove_custom_stopwords(s, stopwords):\n",
    "    for stopword in stopwords:\n",
    "        s = s.replace(stopword, \"\")\n",
    "    return s\n",
    "def lower_case(s):\n",
    "    return s.lower()\n",
    "def preprocess_sentence_fn(s):\n",
    "    # Preprocess a single sentence to a list of tokens\n",
    "    punc_exceptions = ['<', '>']\n",
    "    custom_stopwords = ['dear', 'sincerely', 'thanks', 'yours', 'regards']\n",
    "    filters = [lower_case,\n",
    "               remove_ip,\n",
    "               remove_email,\n",
    "               remove_mailto,\n",
    "               #remove_url,\n",
    "               lambda x: remove_punc(x, punc_exceptions),\n",
    "               remove_stopwords,\n",
    "               lambda x: remove_custom_stopwords(x, custom_stopwords),\n",
    "               strip_multiple_whitespaces,\n",
    "               stem_text,\n",
    "               strip_numeric]\n",
    "    out = preprocess_string(s, filters=filters)\n",
    "    return out\n",
    "def preprocess_docs_fn(docs):\n",
    "    # Apply preprocess_sentence_fn to a list of sentances (docs) to get a list of lists\n",
    "    return [preprocess_sentence_fn(s) for s in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "ticket_dat = pd.read_csv('../data/12-04-ticket_dat.csv')\n",
    "faq_dat = pd.read_csv('../data/12-04-faq_dat.csv')\n",
    "# Replace the NaNs\n",
    "ticket_dat.fillna('', inplace=True)\n",
    "faq_dat.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ question\n",
    "faq_ques = list(faq_dat.question)\n",
    "n_faq_ques = len(faq_ques)\n",
    "# FAQ answer\n",
    "faq_ans = list(faq_dat.answer_title + \" \" + faq_dat.answer)\n",
    "n_faq_ans = len(faq_ans)\n",
    "#ticket question\n",
    "ticket_ques = list(ticket_dat.question)\n",
    "n_ticket_ques = len(ticket_ques)\n",
    "#ticket ans\n",
    "ticket_ans = list(ticket_dat.answer)\n",
    "n_ticket_ans = len(ticket_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Word2Vec model\n",
    "model_path = '../code/embedding/models/word2vec_ticket_ques.model'\n",
    "model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../code/similarity/mappings/ticket_faq_map_word2vec.pkl', 'rb') as fp:\n",
    "    Classes = pickle.load(fp)\n",
    "mapping = Classes['mapping']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_ques_prepro = preprocess_docs_fn(ticket_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_emb(dat):\n",
    "    mean_ans = np.empty((len(dat), 128), dtype=float)\n",
    "    for j in range(len(dat)):\n",
    "        sentence = dat[j]\n",
    "        words = np.empty((len(sentence), 128), dtype=float)\n",
    "        for i in range(len(sentence)):\n",
    "            words[i] = model[sentence[i]]\n",
    "        mean_ans[j] = np.apply_along_axis(np.mean, 0, words)\n",
    "    return mean_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "ticket_question_embeddings = doc_emb(ticket_ques_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV on Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Running CV on Classifier...')\n",
    "classifier_CV = RandomForestClassifier()\n",
    "scores = cross_val_score(classifier_CV, ticket_question_embeddings, mapping, cv=5)\n",
    "cv_score = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9873989538754161 \n",
      " Cross Val Score: 0.21176382289560491\n"
     ]
    }
   ],
   "source": [
    "print('Training Classifier...')\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X=ticket_question_embeddings, y=mapping)\n",
    "#dump(classifier, 'classifier/models/RF_word2vec.joblib')\n",
    "train_score = classifier.score(X=ticket_question_embeddings, y=mapping)\n",
    "\n",
    "print('Training Score: {0} \\n Cross Val Score: {1}'.format(train_score, cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\costanza\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "Bclassifier_CV = GradientBoostingClassifier()\n",
    "scores = cross_val_score(Bclassifier_CV, ticket_question_embeddings, mapping, cv=5)\n",
    "cv_score = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Training Score: 0.8927722301474085 \n",
      " Cross Val Score: 0.2171630096085304\n"
     ]
    }
   ],
   "source": [
    "print('Training Classifier...')\n",
    "Bclassifier = GradientBoostingClassifier()\n",
    "Bclassifier.fit(X=ticket_question_embeddings, y=mapping)\n",
    "#dump(classifier, 'classifier/models/RF_word2vec.joblib')\n",
    "train_score = Bclassifier.score(X=ticket_question_embeddings, y=mapping)\n",
    "\n",
    "print('Training Score: {0} \\nCross Val Score: {1}'.format(train_score, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
